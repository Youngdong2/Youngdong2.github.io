---
layout: single
title: "LangGraph íŠœí† ë¦¬ì–¼ ì™„ë²½ ì •ë¦¬"
categories: LLM
use_math: false
comments: true
toc: true
author_profile: false
---

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ìµœê·¼ ê´€ì‹¬ì´ ë†’ì•„ì§„ LangGraph íŠœí† ë¦¬ì–¼ì— ëŒ€í•´ ì •ë¦¬í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ í¬ìŠ¤íŒ…ì€ [ê³µì‹ íŠœí† ë¦¬ì–¼ ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/tutorials/introduction/)ë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.

ëª©ì°¨ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. LangGraphì˜ ëª©ì 
2. Build a Basic Chatbot
3. Enhancing the Chatbot with Tools
4. Adding Memory to the Chatbot
5. Human-in-the-loop
6. Manually Updating the State
7. Customizing State
8. Time Travel

## LangGraphì˜ ëª©ì 

LangGraphê°€ ë¬´ì—‡ì´ê³  ì™œ ì“°ëŠ” ê²ƒì¼ê¹Œìš”?

LangChainì„ í†µí•´ LLM flowë¥¼ ê°œë°œí•˜ë©´ì„œ í˜ë“¤ì—ˆë˜ ì ì€ ì´ì „ ì²´ì¸ì˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì²´ì¸ìœ¼ë¡œ ë„˜ê¸¸ ë•Œ, ìƒì„±ëœ ê²°ê³¼ì˜ formatì´ ì•ˆë§ëŠ” ë“±ì˜ ì‹¤íŒ¨ë¥¼ ê²ªì–´ë³´ì‹  ì ì´ ëŒ€ë¶€ë¶„ ìˆì„ê²ë‹ˆë‹¤. ì´ëŸ° ê²½ìš° ë³´í†µ Output Parserë¥¼ í†µí•´ í•´ê²°í•˜ê²Œ ë˜ëŠ”ë° ì´ ë°©ë²•ì€ ëª¨ë‹ˆí„°ë§ì„ í•  ë•Œ ì•„ì‰½ë‹¤ë¼ëŠ” ëŠë‚Œì´ ì—†ì§€ ì•ŠìŠµë‹ˆë‹¤.

LangGraphëŠ” LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ì—ì„œ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì—¬ëŸ¬ LLM chain ë˜ëŠ” Agentë¥¼ êµ¬ì¡°í™”ëœ ë°©ì‹ìœ¼ë¡œ ì •ì˜, ì¡°ì • ë° ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ê·¸ëŸ¼ ì´ì œ íŠœí† ë¦¬ì–¼ì„ ì‹œì‘í•´ë³´ì£ !

## Part 1: Build a Basic Chatbot

ì´ ì„¸ì…˜ì—ì„œëŠ” LangGraphë¥¼ ì‚¬ìš©í•´ ì‚¬ìš©ì ë©”ì‹œì§€ì— ì§ì ‘ ì‘ë‹µí•˜ëŠ” ê°„ë‹¨í•œ ì±—ë´‡ì„ ë§Œë“¤ë©´ì„œ, LangGraphì˜ í•µì‹¬ ê°œë…ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ì„¹ì…˜ì´ ëë‚˜ë©´ ê¸°ë³¸ì ì¸ ì±—ë´‡ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1. StateGraph ìƒì„±

LangGraphì—ì„œëŠ” **StateGraph** ê°ì²´ê°€ ì±—ë´‡ì˜ êµ¬ì¡°ë¥¼ "state machine"ë¡œ ì •ì˜í•©ë‹ˆë‹¤. `StateGraph`ì— ë…¸ë“œ(ì±—ë´‡ì´ í˜¸ì¶œí•  LLM ë˜ëŠ” í•¨ìˆ˜)ë¥¼ ì¶”ê°€í•˜ê³ , ì—£ì§€ë¥¼ í†µí•´ ë…¸ë“œ ê°„ì˜ ì „í™˜ì„ ì •ì˜í•©ë‹ˆë‹¤.

```python
from typing import Annotated

from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages


class State(TypedDict):
    # Messages have the type "list". The `add_messages` function
    # in the annotation defines how this state key should be updated
    # (in this case, it appends messages to the list, rather than overwriting them)
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)
```

- `State`í´ë˜ìŠ¤ëŠ” `TypeDict`ë¡œ ì •ì˜ë˜ì–´, ê·¸ë˜í”„ì˜ ìƒíƒœê°€ ë©ë‹ˆë‹¤.
- ì—¬ê¸°ì—ëŠ” `messages`ë¼ëŠ” ë‹¨ì¼ í‚¤ê°€ ìˆìœ¼ë©°, `add_messages`í•¨ìˆ˜ë¡œ ë©”ì‹œì§€ê°€ ê¸°ì¡´ ìƒíƒœì— ì¶”ê°€ë˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.
- `graph_builder`ëŠ” `StateGraph`ë¡œ ì´ˆê¸°í™”ë˜ì–´, `State`ì˜ ìŠ¤í‚¤ë§ˆì™€ ìƒíƒœ ê°±ì‹  ë°©ì‹ì¸ reducer í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

> **Note**: ê·¸ë˜í”„ë¥¼ ì •ì˜í•  ë•Œ ì²« ë²ˆì§¸ ì‘ì—…ì€ **State**ë¥¼ ì •ì˜í•˜ëŠ” ê²ƒ. StateëŠ” ê·¸ë˜í”„ì˜ ìŠ¤í‚¤ë§ˆì™€ ìƒíƒœ ì—…ë°ì´íŠ¸ ë°©ì‹ì„ ì •ì˜í•˜ëŠ”ë°, ì—¬ê¸°ì„œ `messages`í‚¤ëŠ” **add_messages** reducer í•¨ìˆ˜ê°€ ì ìš©ë˜ì–´ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ë®ì–´ì“°ì§€ ì•Šê³  ê¸°ì¡´ ëª©ë¡ì— ì¶”ê°€ë˜ë„ë¡ í•©ë‹ˆë‹¤. Annotated ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë®ì–´ì“°ê¸° ë°©ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.

ì´ë¡œì¨ ê·¸ë˜í”„ëŠ” ë‘ ê°€ì§€ë¥¼ ì•Œê²Œ ë©ë‹ˆë‹¤.

1. ìš°ë¦¬ê°€ ì •ì˜í•  ëª¨ë“  ë…¸ë“œëŠ” í˜„ì¬ ìƒíƒœë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê°’ì„ ë°˜í™˜
2. `messages`ëŠ” ë®ì–´ì“°ê¸°ê°€ ì•„ë‹Œ **add_messages** í•¨ìˆ˜ë¥¼ í†µí•´ ê¸°ì¡´ ëª©ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€

### 2. ì±—ë´‡ ë…¸ë“œ ì¶”ê°€

ì´ì œ "chatbot" ë…¸ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. ë…¸ë“œëŠ” ì‘ì—… ë‹¨ìœ„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê³µì‹ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” **ChatAntropic** ëª¨ë¸ì„ ì‚¬ìš©í•´ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì±—ë´‡ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
from langchain_anthropic import ChatAnthropic

llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")


def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}


# ì²« ë²ˆì§¸ ì¸ìëŠ” ë…¸ë“œì˜ ê³ ìœ  ì´ë¦„
# ë‘ ë²ˆì§¸ ì¸ìëŠ” ë…¸ë“œê°€ í˜¸ì¶œë  ë•Œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜ ë˜ëŠ” ê°ì²´
graph_builder.add_node("chatbot", chatbot)
```

- chatbot í•¨ìˆ˜ëŠ” í˜„ì¬ Stateë¥¼ ì…ë ¥ë°›ê³ , ê°±ì‹ ëœ `messages` ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ ëª¨ë“  LangGraph ë…¸ë“œ í•¨ìˆ˜ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.
- ë‹¤ìŒìœ¼ë¡œ, **add_node** ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ ì±—ë´‡ ë…¸ë“œë¥¼ ê·¸ë˜í”„ì— ì¶”ê°€í•©ë‹ˆë‹¤.

> **Note** : ì—¬ê¸°ì—ì„œ `chatbot` ë…¸ë“œ í•¨ìˆ˜ëŠ” í˜„ì¬ ìƒíƒœë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , `messages`í‚¤ ì•„ë˜ì— ê°±ì‹ ëœ ë©”ì‹œì§€ ëª©ë¡ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. LangGraphëŠ” `add_messages` í•¨ìˆ˜ë¥¼ í†µí•´ LLMì˜ ì‘ë‹µì„ í˜„ì¬ ìƒíƒœì— ìˆëŠ” ë©”ì‹œì§€ ëª©ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.

### 3. ì‹œì‘ì ê³¼ ì¢…ë£Œì  ì„¤ì •

ì´ì œ ì±—ë´‡ì˜ ì‹œì‘ì ê³¼ ì¢…ë£Œì ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì‹œì‘ì ì€ ê·¸ë˜í”„ê°€ ê° ì‹¤í–‰ ì‹œ ì‘ì—…ì„ ì‹œì‘í•  ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ë©°, ì¢…ë£Œì ì€ íŠ¹ì • ë…¸ë“œê°€ ì‹¤í–‰ë˜ë©´ ìŠ¤ë˜í”„ê°€ ì¢…ë£Œë  ìˆ˜ ìˆìŒì„ ì•Œë ¤ì¤ë‹ˆë‹¤.

```python
graph_builder.add_edge(START, "chatbot") # ì‹œì‘ì  ì„¤ì •
graph_builder.add_edge("chatbot", END) # ì¢…ë£Œì  ì„¤ì •
```

### 4. ê·¸ë˜í”„ ì»´íŒŒì¼ ë° ì‹¤í–‰

ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ë©´, `compile()`ì„ í˜¸ì¶œí•˜ì—¬ ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•©ë‹ˆë‹¤.
**CompiledGraph** ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘ì„ ìˆ˜í–‰í•˜ê²Œ ë©ë‹ˆë‹¤.

```python
graph = graph_builder.compile()
```

ë˜í•œ `get_graph`ë©”ì„œë“œì™€ `draw_ascii` ë˜ëŠ” `draw_png` ì™€ ê°™ì€ ê·¸ë¦¬ê¸° ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # ì‹œê°í™”ì— ì¶”ê°€ ì¢…ì†ì„±ì´ í•„ìš”
    pass
```

<p align="center">
  <img src="/images/langgraph/langgraph1.jpeg" height="200px" width="100px">
</p>

### 5. ì±—ë´‡ ì‹¤í–‰í•˜ê¸°

ì´ì œ ì±—ë´‡ê³¼ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ëŒ€í™” ë£¨í”„ë¥¼ ë§Œë“­ë‹ˆë‹¤. `stream_graph_updates`í•¨ìˆ˜ëŠ” ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì±—ë´‡ì˜ ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” "quit", "exit" ë˜ëŠ” "q"ë¥¼ ì…ë ¥í•´ ëŒ€í™”ë¥¼ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
def stream_graph_updates(user_input: str):
    for event in graph.stream({"messages": [("user", user_input)]}):
        for value in event.values():
            print("Assistant:", value["messages"][-1].content)


while True:
    try:
        user_input = input("User: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Goodbye!")
            break

        stream_graph_updates(user_input)
    except:
        # fallback if input() is not available
        user_input = "What do you know about LangGraph?"
        print("User: " + user_input)
        stream_graph_updates(user_input)
        break
```

```text
Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, stateful AI applications that go beyond simple query-response interactions.
Goodbye!
```

## Part 2: Enhancing the Chatbot with Tools

ì´ë²ˆì—ëŠ” ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ í†µí•©í•˜ì—¬ ë‹µë³€ì„ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ì‹œë‹¤.

ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  API í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Tavily ê²€ìƒ‰ ì—”ì§„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
%%capture --no-stderr
%pip install -U tavily-python langchain_community

_set_env("TAVILY_API_KEY")
```

### 1. Tool ì •ì˜

Tavily ê²€ìƒ‰ ë„êµ¬ë¥¼ ì •ì˜í•˜ì—¬, ì±—ë´‡ì´ 'LangGraphì˜ ë…¸ë“œê°€ ë¬´ì—‡ì¸ê°€ìš”?'ì™€ ê°™ì€ ì§ˆë¬¸ì— ì›¹ ê²€ìƒ‰ì„ í†µí•´ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

```python
from langchain_community.tools.tavily_search import TavilySearchResults

tool = TavilySearchResults(max_results=2)
tools = [tool]
tool.invoke("What's a 'node' in LangGraph?")
```

ì´ë•Œ, Tavily ê²€ìƒ‰ ë„êµ¬ëŠ” í˜ì´ì§€ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•˜ì—¬ ì±—ë´‡ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 2. StateGraph ë° LLM ì´ˆê¸°í™”

ê¸°ë³¸ì ì¸ StateGraph ìƒì„± ì½”ë“œëŠ” part1ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, **bind_tools** ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì´ JSON í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ì—”ì§„ì„ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
# Modification: tell the LLM which tools it can call
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)
```

ì´ë ‡ê²Œ í•˜ë©´ LLMì´ ì ì ˆí•œ JSON í˜•ì‹ìœ¼ë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 3. Tool ì‹¤í–‰ ë…¸ë“œ ì¶”ê°€

Toolì´ í˜¸ì¶œë  ê²½ìš° ì´ë¥¼ ì‹¤í–‰í•˜ëŠ” **BasicToolNode** í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì´ ë…¸ë“œëŠ” ìµœê·¼ ë©”ì‹œì§€ì—ì„œ `tool_calls`ê°€ í¬í•¨ëœ ê²½ìš° toolì„ í˜¸ì¶œí•©ë‹ˆë‹¤.

```python
import json

from langchain_core.messages import ToolMessage


class BasicToolNode:
    """AIMesageì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— í¬í•¨ëœ ë„êµ¬ ìš”ì²­ì„ ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ."""

    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}

    def __call__(self, inputs: dict):
        if messages := inputs.get("messages", []):
            message = messages[-1]
        else:
            raise ValueError("No message found in input")
        outputs = []
        for tool_call in message.tool_calls:
            tool_result = self.tools_by_name[tool_call["name"]].invoke(
                tool_call["args"]
            )
            outputs.append(
                ToolMessage(
                    content=json.dumps(tool_result),
                    name=tool_call["name"],
                    tool_call_id=tool_call["id"],
                )
            )
        return {"messages": outputs}


tool_node = BasicToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)
```

ìœ„ì˜ `BasicToolNode`ëŠ” ë©”ì‹œì§€ì—ì„œ `tool_calls`ê°€ ìˆëŠ”ì§€í™•ì¸í•˜ì—¬ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

### 4. ì¡°ê±´ë¶€ ì—£ì§€ ì„¤ì •

ì¡°ê±´ë¶€ ì—£ì§€ëŠ” íŠ¹ì • ì¡°ê±´ì— ë”°ë¼ ë…¸ë“œ ê°„ íë¦„ì„ ì œì–´í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” **route_tools** í•¨ìˆ˜ë¡œ `tool_calls`ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆëŠë©´ `tools`ë¡œ, ì—†ìœ¼ë©´ `END`ë¡œ ì´ë™í•©ë‹ˆë‹¤.

```python
from typing import Literal


def route_tools(
    state: State,
):
    """
    Use in the conditional_edge to route to the ToolNode if the last message
    has tool calls. Otherwise, route to the end.
    """
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"No messages found in input state to tool_edge: {state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return END

graph_builder.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", END: END},
)
# Any time a tool is called, we return to the chatbot to decide the next step
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
graph = graph_builder.compile()
```

ì´ì œ `chatbot` ë…¸ë“œê°€ ì‹¤í–‰ë  ë•Œë§ˆë‹¤ `tool_calls`ê°€ ìˆìœ¼ë©´ `tools`ë¡œ, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ `END`ë¡œ ì´ë™í•˜ë„ë¡ í•©ë‹ˆë‹¤.

#### 5. ê·¸ë˜í”„ ì‹œê°í™” ë° ì‹¤í–‰

```python

from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass
```

<p align="center">
  <img src="/images/langgraph/langgraph2.jpeg" height="200px" width="150px">
</p>

ì´ì œ ì±—ë´‡ì€ í•™ìŠµ ë°ì´í„° ì™¸ë¶€ì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš©ì ì…ë ¥ì— ë”°ë¼ Tavily ê²€ìƒ‰ ì—”ì§„ì„ í†µí•´ ì •ë³´ë¥¼ ì°¾ê³  ì œê³µí•©ë‹ˆë‹¤.

```python
while True:
    try:
        user_input = input("User: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Goodbye!")
            break

        stream_graph_updates(user_input)
    except:
        # fallback if input() is not available
        user_input = "What do you know about LangGraph?"
        print("User: " + user_input)
        stream_graph_updates(user_input)
        break
```

ì˜ˆì‹œ ì‘ë‹µ:

```css
Assistant: [{"url": "https://www.langchain.com/langgraph", "content": "LangGraphëŠ” ë³µì¡í•œ AI ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤..."}]
```

## Part3: Adding Memory to the Chatbot

Part2ê¹Œì§€ì˜ ê³¼ì •ì„ í†µí•´ ì±—ë´‡ì´ toolì„ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆì§€ë§Œ, ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê¸°ì–µí•˜ì§€ëŠ” ëª»í•©ë‹ˆë‹¤.
ì´ëŠ” ë©€í‹°í„´ ëŒ€í™”ì˜ ì—°ì†ì„±ì„ ìœ ì§€í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. **LangGraph**ëŠ” ì§€ì†ì ì¸ ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œì„ í†µí•´ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

### LangGraphì˜ Checkpointing ì‹œìŠ¤í…œ

LangGraphì—ì„œ ì²´í¬í¬ì¸í„°ì™€ `thread_id`ë¥¼ ì§€ì •í•´ ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•˜ë©´, ê·¸ë˜í”„ëŠ” ê° ë‹¨ê³„ í›„ ìƒíƒœë¥¼ ìë™ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ë™ì¼í•œ `thred_id`ë¡œ ë‹¤ì‹œ í˜¸ì¶œí•˜ë©´ ì €ì¥ëœ ìƒíƒœê°€ ë¡œë“œë˜ì–´ ì±—ë´‡ì´ ì´ì „ ëŒ€í™”ì—ì„œ ì´ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> **Note**: 
> Checkpoingì€ ë‹¨ìˆœí•œ ë©”ëª¨ë¦¬ ì´ìƒì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ì—ëŸ¬ ë³µêµ¬, human-in-the-loop ì›Œí¬í”Œë¡œìš°, time travel interactions ë“±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ë¨¼ì € ë©€í‹°í„´ ëŒ€í™”ë¥¼ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì¶”ê°€í•´ ë³´ê² ìŠµë‹ˆë‹¤.

### 1. ë©”ëª¨ë¦¬ saver ìƒì„±

ë¨¼ì € **MemorySaver** ì²´í¬í¬ì¸í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
```

ì´ ì²´í¬í¬ì¸í„°ëŠ” ë©”ëª¨ë¦¬ì— ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” SQLiteë‚˜ PostgreSQLê³¼ ê°™ì€ DBì— ì—°ê²°í•  ìˆ˜ ìˆëŠ” **SqliteSaver**ë‚˜ **PostgresSaver**ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì‡ìŠµë‹ˆë‹¤.

### 2. ê·¸ë˜í”„ ì •ì˜ ë° ì»´íŒŒì¼

ê¸°ì¡´ì˜ **BasicToolNode** ëŒ€ì‹  LangGraphì˜ **ToolNode**ì™€ **tools_condition**ì„ ì‚¬ìš©í•˜ì—¬ ë” íš¨ìœ¨ì ì€ API ì„¤í–‰ì„ êµ¬ì„±í•©ë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì½”ë“œ êµ¬ì¡°ëŠ” part2ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤.

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
# Any time a tool is called, we return to the chatbot to decide the next step
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
```

ì´ì œ ì²´í¬í¬ì¸í„°ì™€ í•¨ê»˜ ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•©ë‹ˆë‹¤.

```python
graph = graph_builder.compile(checkpointer=memory)
```

### 3. ì±—ë´‡ê³¼ ìƒí˜¸ì‘ìš©

ê° ëŒ€í™”ì˜ **thread_id**ë¥¼ í†µí•´ ì±—ë´‡ì´ ëŒ€í™” ë§¥ë½ì„ ê¸°ì–µí•˜ê²Œ ë©ë‹ˆë‹¤.

```python
config = {"configurable": {"thread_id": "1"}}
```

ë‹¤ìŒê³¼ ê°™ì´ ì±—ë´‡ì„ í˜¸ì¶œí•´ë´…ì‹œë‹¤.

```python
user_input = "Hi there! My name is Will."

# The config is the **second positional argument** to stream() or invoke()!
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    event["messages"][-1].pretty_print()
```

ì‘ë‹µ ì˜ˆ:

```text
================================ Human Message =================================
Hi there! My name is Will.
================================= Ai Message ===================================
Hello Will! It's nice to meet you. How can I assist you today?

```

ì´ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

```python
user_input = "Remember my name?"

# The config is the **second positional argument** to stream() or invoke()!
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    event["messages"][-1].pretty_print()
```

```text
================================ Human Message =================================
Remember my name?
================================= Ai Message ===================================
Of course, I remember your name, Will. Is there anything else you'd like to talk about?
```

> **Note**:
> ë©”ëª¨ë¦¬ëŠ” LangGraphì˜ ì²´í¬í¬ì¸í„°ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ, ì™¸ë¶€ ë¦¬ìŠ¤íŠ¸ë‚˜ ì¶”ê°€ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ìƒˆë¡œìš´ `thread_id`ë¡œ í˜¸ì¶œí•˜ë©´ ì±—ë´‡ì€ ì´ˆê¸° ìƒíƒœë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.

```python
# The only difference is we change the `thread_id` here to "2" instead of "1"
events = graph.stream(
    {"messages": [("user", user_input)]},
    {"configurable": {"thread_id": "2"}},
    stream_mode="values",
)
for event in events:
    event["messages"][-1].pretty_print()
```

```text
================================ Human Message =================================
Remember my name?
================================= Ai Message ===================================
I apologize, but I don't have any previous context or memory of your name. Could you please tell me your name?
```

ë‹¨ìˆœíˆ `thread_id`ë§Œ ë³€ê²½í–ˆìŒì—ë„ ì±—ë´‡ì€ ìƒˆë¡œìš´ ëŒ€í™”ë¡œ ì¸ì‹í•©ë‹ˆë‹¤.

### ìƒíƒœ ìŠ¤ëƒ…ìƒ· ê²€ì‚¬í•˜ê¸°

**get_state** ë©”ì„œë“œë¥¼ í†µí•´ í˜„ì¬ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
snapshot = graph.get_state(config)
snapshot
```

```text
StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8c1ca919-c553-4ebf-95d4-b59a2d61e078'), AIMessage(content="Hello Will! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to know or discuss?", additional_kwargs={}, response_metadata={'id': 'msg_01WTQebPhNwmMrmmWojJ9KXJ', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 405, 'output_tokens': 32}}, id='run-58587b77-8c82-41e6-8a90-d62c444a261d-0', usage_metadata={'input_tokens': 405, 'output_tokens': 32, 'total_tokens': 437}), HumanMessage(content='Remember my name?', additional_kwargs={}, response_metadata={}, id='daba7df6-ad75-4d6b-8057-745881cea1ca'), AIMessage(content="Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.", additional_kwargs={}, response_metadata={'id': 'msg_01E41KitY74HpENRgXx94vag', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 444, 'output_tokens': 58}}, id='run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 58, 'total_tokens': 502})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7d06e-93e0-6acc-8004-f2ac846575d2'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content="Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.", additional_kwargs={}, response_metadata={'id': 'msg_01E41KitY74HpENRgXx94vag', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 444, 'output_tokens': 58}}, id='run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 58, 'total_tokens': 502})]}}, 'step': 4, 'parents': {}}, created_at='2024-09-27T19:30:10.820758+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7d06e-859f-6206-8003-e1bd3c264b8f'}}, tasks=())
```

ì´ ìŠ¤ëƒ…ìƒ·ì—ëŠ” í˜„ì¬ ìƒíƒœ, í•´ë‹¹ ì„¤ì •, ë‹¤ìŒ ì²˜ë¦¬ ë…¸ë“œê°€ í¬í•¨ë©ë‹ˆë‹¤. ì´ ì˜ˆì‹œì—ì„œëŠ” ê·¸ë˜í”„ê°€ `END`ìƒíƒœì— ë„ë‹¬í–ˆìœ¼ë¯€ë¡œ `next`ëŠ” ë¹„ì–´ìˆìŠµë‹ˆë‹¤.

## Part4: Human-in-the-loop

Agentê°€ ëª¨ë“  ì‘ì—…ì„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ìˆ˜í–‰í•˜ì§€ ëª»í•  ë•ŒëŠ” ì¸ê°„ì˜ ê²€í† ë‚˜ ì…ë ¥ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
LangGraphëŠ” **interrupt_before** ê¸°ëŠ¥ì„ í†µí•´ íŠ¹ì • ë…¸ë“œì—ì„œ ì‘ì—…ì„ ì¼ì‹œì¤‘ì§€í•˜ê³ , ì¸ê°„ì´ ê²€í† í•˜ê±°ë‚˜ ìŠ¹ì¸í•œ í›„ì—ë§Œ ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

ì´ë²ˆ íŒŒíŠ¸ì—ì„œëŠ” **tool** ë…¸ë“œ ì‹¤í–‰ ì „ë§ˆë‹¤ ì‘ì—…ì„ ì¤‘ë‹¨í•˜ë„ë¡ ì„¤ì •í•˜ì—¬ ì¸ê°„ ê²€í† ê°€ í•„ìš”í•  ë•Œ ê°œì…í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.

### 1. ê¸°ì¡´ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°

ì´ ì„¹ì…˜ì˜ ì½”ë“œëŠ” part 3ì˜ ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from typing_extensions import TypedDict

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

memory = MemorySaver()


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)

tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
```

### 2. ê·¸ë˜í”„ ì»´íŒŒì¼ ë° ì¤‘ë‹¨ ì§€ì  ì„¤ì •

**interrupt_before** ì¸ìˆ˜ë¥¼ í†µí•´ `tools`ë…¸ë“œ ì‹¤í–‰ ì „ ì‘ì—…ì„ ì¤‘ë‹¨í•˜ë„ë¡ ì§€ì •í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¸ê°„ ê²€í†  í›„ ì‘ì—…ì„ ì¬ê°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
graph = graph_builder.compile(
    checkpointer=memory,
    # This is new!
    interrupt_before=["tools"],
)
```

### 3. ì±—ë´‡ê³¼ ìƒí˜¸ì‘ìš© ë° ê²€í† 

ì•„ë˜ ì½”ë“œëŠ” ì±—ë´‡ì— ì…ë ¥ì„ ì „ë‹¬í•˜ê³ , ì¤‘ë‹¨ ì§€ì ì—ì„œ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

```python
user_input = "I'm learning LangGraph. Could you do some research on it for me?"
config = {"configurable": {"thread_id": "1"}}

events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

ì¶œë ¥ ì˜ˆ:

```test
================================[1m Human Message [0m=================================

I'm learning LangGraph. Could you do some research on it for me?
==================================[1m Ai Message [0m==================================

[{'text': "Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.", 'type': 'text'}, {'id': 'toolu_01R4ZFcb5hohpiVZwr88Bxhc', 'input': {'query': 'LangGraph framework for building language model applications'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]
Tool Calls:
  tavily_search_results_json (toolu_01R4ZFcb5hohpiVZwr88Bxhc)
 Call ID: toolu_01R4ZFcb5hohpiVZwr88Bxhc
  Args:
    query: LangGraph framework for building language model applications
```

ì´ ì‹œì ì—ì„œ **graph.get_state(config)**ë¡œ ìƒíƒœë¥¼ í™•ì¸í•˜ì—¬ `tools`ë…¸ë“œì— ì¤‘ë‹¨ëœ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
snapshot = graph.get_state(config)
snapshot.next
```

```text
('tools',)
```

**next** ê°’ì´ `tools`ë¡œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´, ì¤‘ë‹¨ëœ ìƒíƒœì—ì„œ ê²€í† ë¥¼ ìˆ˜í–‰í•œ ìˆ˜ ì‘ì—…ì„ ê³„ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 4. ì‘ì—… ì¬ê°œ

ê²€í†  í›„ `None`ì„ ì „ë‹¬í•´ ê·¸ë˜í”„ê°€ ì¤‘ë‹¨ëœ ì§€ì ì—ì„œ ì´ì–´ì„œ ì‹¤í–‰ë˜ë„ë¡ í•©ë‹ˆë‹¤.

```python
events = graph.stream(None, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

ì±—ë´‡ì€ ì´ì „ ì¤‘ë‹¨ ì§€ì ì—ì„œ ì´ì–´ë°›ì•„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì´ì œ **interrupt_before**ê¸°ëŠ¥ì„ í™œìš©í•´ ì¸ê°„ì˜ ê°œì…ì„ ìš”êµ¬í•˜ëŠ” ë‹¨ê³„ì—ì„œ ì‘ì—…ì„ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ agentì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê³ , í•„ìš”í•œ ê²½ìš° ì¸ê°„ì˜ ê²€í†  í›„ ì‘ì—…ì„ ì´ì–´ê°ˆ ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

LangGraphì˜ ì²´í¬í¬ì¸í„°ê°€ ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì‘ì—…ì„ ë¬´ê¸°í•œ ì¤‘ë‹¨í•˜ê³  ì–¸ì œë“ ì§€ ì´ì–´ì„œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì—¬ê¸°ê¹Œì§€ LangGraphë¥¼ í™œìš©í•œ ì±—ë´‡ êµ¬ì¶•ì˜ íë¦„ì„ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. ëê¹Œì§€ ì •ë¦¬ë¥¼ í•˜ë©´ í¬ìŠ¤íŒ…ì´ ë„ˆë¬´ ê¸¸ì–´ì§ˆ ê²ƒ ê°™ì•„ ë‚˜ë¨¸ì§€ íŒŒíŠ¸ëŠ” ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ì„œ ì •ë¦¬í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

ê¸´ ê¸€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!