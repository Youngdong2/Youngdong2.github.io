---
layout: single
title: "[Paper Review] Causal Discovery with Attention Based Convolutional Neural Network(TCDF)"
categories: Paper_Review
use_math: true
comments: ture
toc: true
author_profile: false
---
이번 포스팅에서는 시계열 데이터의 인과그래프를 탐색하는 논문을 리서치하던 중 인용수가 많았던 Causal Discovery with Attention_Based Convolutional Neural Network를 리뷰해보고자 합니다.  
최근 업무에서 IT서비스의 성능 표인 시계열 데이터의 인과관계를 추론하여 장애가 발생하였을 때 원인이 무엇인지 탐색하는 Root Cause Analysis(RCA)에 대한 연구를 진행하고 있습니다. 이 논문의 목적이 RCA는 아니지만 시계열의 인과관계를 추론하는 데에 연구목적과 맞기 때문에 포스팅을 하게 되었습니다.

## Abstract

먼저 초록을 정리해보면 다음과 같습니다.  

* 시계열 데이터에서 인과 관계를 발견하여 인과 그래프를 학습하는 딥러닝 framework인 TCDF를 제안한다.
* CNN의 내부 파라미터를 해석하여 원인과 결과 발생 사이의 시간 지연도 발견할 수 있다.
* 금융 및 신경과학 벤치마크에 대한 실험은 시계열 데이터에서 인과 관계를 발견하는 데 있어 TCDF의 높은 성능을 보여준다.
* 광범위하게 적용 가능하기 때문에 지식 발견 및 복잡한 시스템의 인과 관계에 대한 새로운 인사이트를 얻는 데 사용할 수 있다.

Introduction은 초록과 비슷하기 때문에 생략하도록 하겠습니다.

## Problem Statement

본 논문에서의 **Temporal causal discovery**는 길이가 $T$이고, 변수의 개수가 $N$인 시계열 데이터 $X=\{ X_1,X_2,...,X_N \} \in \mathbb{R}^{N \times T}$가 주어졌을 때, $X$의 모든 $N$개의 시계열과 원인과 결과 사이의 시간 지연 사이의 인과관계를 발견하고 시간적 인과관계 그래프로 모형화하는 것으로 정의합니다.  
인과그래프 $g=(V,E)$ 에서 노드 $v_i \in V$는 $i$번째 시계열 데이터 $X_i$를 의미하고, 엣지 $e_{i,j}$는 노드 $v_i$와 노드 $v_j$의 관계를 나타냅니다. 즉, $X_i$가 $X_j$의 원인임을 나타냅니다.  
또한, $p=<v_i,...,v_j>$는 $g$의 $v_i$부터 $v_j$까지의 path를 나타내며, temporal causal graph에서 모든 엣지는 가중치 $d(e_{i,j})$가 있으며, 이는 이는 원인 $X_i$의 발생과 결과 $X_j$의 발생 사이의 시간 지연을 나타냅니다. 예시를 확인해보면 다음과 같습니다.

![fig1]({{site.url}}/images/Paper_Review/TCDF1.png){: width="700" height="700"}

인과 관계가 복잡할 경우 Causal Discovery는 다음과 같은 어려움이 있습니다.

* 모델은 직접 원인과 간접 원인을 구별해야 합니다. fig2-a와 같이 $v_i$가 $v_j$의 간접 원인이고, $p=<v_i, v_k, v_j> \in g$일 때 Pairwise방법은 즉, 두 변수 사이의 인과관계만을 찾는 방법은 종종 이러한 구분을 할 수 없습니다. 하지만, 다변량 방법은 직접적인 인과 관계와 간접적인 인과 관계를 구별하기 위해 모든 변수를 고려합니다.
* 모델은 원인과 결과 사이의 지연이 0인 즉각적 인과 효과를 학습해야 합니다. 순간적인 영향을 무시하면 오해의 소지가 있는 해석을 초래할 수 있습니다. 이는 대부분 원인과 결과의 시간적 척도가 너무 coarse하여 인과적 정렬을 할 수 없을 때 발생합니다.
* **Confounder**의 존재는 인과관계에서 잘 알려진 challenge입니다.(fig2-b) confounder는 상관관계는 있지만 인과관계는 없기 때문에 confounder의 효과로 인해 긴과관계를 잘못 포함하지 않도록 주의해야 합니다. confounder에 대한 자세한 설명은 제가 포스팅한 [인과그래프](https://youngdong2.github.io/causal_inference/causal_inference3/)에서 확인해보실 수 있습니다.
* confounder가 관찰되지 않을 때(숨겨진(또는 잠재된) confounder) 특별한 도전이 발생합니다. 비록 얼마나 많은 숨겨진 confounder가 존재하는지조차 알 수 없을 수 있지만, 인과 추론 방법이 숨겨진 confounder의 존재를 가설로 설정하여 그 효과 사이의 잘못된 인과 관계를 학습하는 것을 방지하는 것이 중요합니다.

![fig2]({{site.url}}/images/Paper_Review/TCDF2.png){: width="700" height="700"}

## TCDF - Temporal Causal Discovery Framework

![fig3]({{site.url}}/images/Paper_Review/TCDF3.png){: width="700" height="700"}

이제 자세하게 본 논문에서 제안하는 framework에 대해 알아보겠습니다.  
TCDF는 크게 네가지 단계(Time Series Prediction, Attention Interpretation, Causal Validation, Delay Discovery)로 구성됩니다.  
TCDF는 $N$개의 독립적인 attention-based CNN으로 구성되어 있는데 모두 같은 구조로 되어있지만 fig4에서 확인할 수 있듯이 target 변수가 다릅니다. 이는 $j$번째 네트워크 $\mathcal{N_j}$는 target인 $X_j$를 예측하는 것을 의미합니다.  
$\mathcal{N_j}에서 $X_j$를 예측하기 위해 학습되고, attention score $a_j$는 