---
layout: single
title: "You Only Look Once(YOLO)"
categories: Paper_Review
use_math: true
comments: ture
toc: true
author_profile: false
---
이번 포스팅에서는 지난 7월에 풀입스쿨 논문요약 스터디에서 다뤘던 YOLO에 대해 요약해보려 합니다.  
제조 AI에 관심이 있는데 CV쪽을 알아두면 좋을 것 같아 참여하게 되었습니다.

## Abstract

### Object Detection의 새로운 접근법

* 선행 연구에서는 분류기를 사용하여 탐지를 수행.
* 본 논문에서는 bounding box와 관련 클래스의 확률에 대한 회귀문제로 해결.
* 전체 파이프라인이 하나의 네트워크로 이루어져 있기 때문에 end-to-end로 최적화가 가능.
* YOLO의 아키텍쳐는 초당 45프레임의 이미지를 실시간으로 처리할 수 있기 때문에 굉장히 빠르다.

## Introduction

![fig1]({{site.url}}/images/Paper_Review/YOLO1.png)

* YOLO는 객체 탐지를 이미지 픽셀에서 bounding box의 좌표와 각 클래스의 확률을 구하는 문제로 해결한다.
* End-to-end 방색의 통합된 구조로 되어 있으며, 이미지를 CNN에 한 번 평가하는 것을 통해서 동시에 다수의 bounding box와 클래스 확률을 구하게 된다.
* 이러한 통합모델로 인해 YOLO는 몇 가지 장점을 가지게 됨  
  1. Titan X에서 45fps를 달성하며 빠른 버전의 경우 150fps의 빠른 성능을 보이고 다른 실시간 시스템 대비 2배 이상의 mAP의 성능을 보인다.
  2. Sliding window 방식이 아닌 CNN을 사용하는 것으로 인해 전체 이미지를 보게끔 유도되어 각 class에 대한 표현을 더 잘 학습함.
  3. 일반화된 Object의 표현을 학습한다. 실험적으로 자연의 dataset을 학습시킨 후 학습시킨 네트워크에 artwork 이미지를 입력했을 때, 선행 연구 대비 좋은 detection 성능을 보인다.

## Unified Detection

