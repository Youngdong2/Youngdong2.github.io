---
layout: single
title: "말 잘 듣는 LLM 만들기"
categories: LLM
use_math: false
comments: true
toc: true
author_profile: false
---

LLM은 다음 단어를 예측하는 방식으로 대량의 텍스트를 학습해서 뛰어난 텍스트 생성 능력을 보여줬습니다.  
2020년 OpenAI가 GPT-3를 발표했을 때 생성 결과의 퀄리티는 좋았지만, 사용자의 요청에 적절히 응답하기보다는 사용자의 말에 이어질 법한 텍스트를 생성한다는 한계를 지니고 있었습니다.  

그렇다면 GPT-3는 어떻게 ChatGPT가 될 수 있었을까요?  
Open-AI는 두 단계를 거쳐 GPT-3를 ChatGPT로 변화시켰습니다. 먼저, 요청(또는 질문)과 답변 형식으로 된 **instruction dataset**을 통해 GPT-3가 사용자의 요청에 응답할 수 있도록 학습시켰습니다. 다음으로 사용자가 더 좋아하고 사용자에게 더 도움이 되는 답변을 생성할 수 있도록 추가학습을 시켰습니다. 이를 사용자 선호를 학습한다고 합니다.  
선호를 학습한 LLM은 더 정제된 답변을 생성하게 됩니다.  

이번 포스팅에서는 사람들이 더 선호하는 답변을 생성할 수 있도록 모델을 조정하는 방법에 대해 알아봅니다.

## 사전 학습과 fine tuning

### 1. LLM의 사전 학습

LLM은 보통 인터넷상에 있는 다양한 텍스트 데이터를 수집한 대용량의 텍스트로 사전 학습합니다.  
2023년 메타가 공개한 LLama-2는 약 10TB 분량의 텍스트를 사전 학습에 사용했는데 이 데이터의 경우 코드, 블로그, 기사, 광고 등 다양한 글이 섞여 있기 때문에 사전 학습 데이터에서 다음 단어를 예측하는 방법으로 학습하는 경우 LLM이 특정한 형태로 응답하거나 사용자의 요청에 따라 응답하길 기대하기는 어렵습니다.  
사전 학습 동안 LLM이 언어에 대한 전체적인 이해도가 높아지고 바로 다음에 올 단어를 점점 더 잘 예측하게 됩니다.  

### 2. Supervised fine-tuning

LLM이 사용자의 요청에 적절히 응답하기 위해서는 요청의 형식을 적절히 해석하고, 응답의 형태를 적절히 작성하며, 요청과 응답이 잘 연결되도록 추가로 학습해야합니다. 이를 **supervised fine-tuning**이라고 합니다. 여기서 supervised는 학습 데이터에 정답이 포함되어 있다는 의미입니다.
supervised fine-tuning를 통해 LLM은 사용자 요청에 맞춰 응답하도록 학습하는데, 이를 **alignment**라고 합니다. 사람의 요청과 LLM의 응답이 정렬되도록 한다는 의미죠.

이 때 사용하는 데이터셋을 **instruction dataset**이라고 합니다. 많고 질 좋은 이 데이터셋을 구하기는 굉장히 힘듭니다.
이런 문제를 보완하기 위해 사용자의 요구사항과 그에 대단 응답을 구조화한 데이터를 구축하고 언어 모델의 학습에 활용합니다.
2023년 스탠퍼드에서 오픈소스 Llama 모델을 추가 학습한 Alpaca를 공개할 때 사용한 알파카 데이터셋을 살펴보죠. 

```text
{
    "instruction": "Create a classification task by clustering the given list of items.",
    "input": "Apples, oranges, bananas, strawberries, pineapples",
    "output": "Class 1: Apples, Oranges\nClass 2: Bananas, Strawberries\nClass 3: Pineapples",
    "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nCreate a classification task by clustering the given list of items.\n\n### Input:\nApples, oranges, bananas, strawberries, pineapples\n\n### Response:\nClass 1: Apples, Oranges\nClass 2: Bananas, Strawberries\nClass 3: Pineapples",
}
```

instruction은 사용자의 요구사항을 표현한 문장입니다. input에는 답변을 하는 데 필요한 데이터가 들어가고, output은 정답 응답, text에는 instruction, input, output을 정해진 포맷으로 하나로 묶은 데이터입니다.  

위 예시는 아직 특정한 형식을 갖추지는 않았는데, 아래같은 템플릿 형태로 맞춰줍니다. 이때 LLM이 데이터의 형식을 인식할 수 있도록 ###으로 텍스트를 구분합니다.

```python
f"""
Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
Create a classification task by clustering the given list of items.

### Input:
Apples, oranges, bananas, strawberries, pineapples

### Response:
Class 1: Apples, Oranges
Class 2: Bananas, Strawberries
Class 3: Pineapples
"""
```

이제 LLM이 사람이 더 선호하는 방식으로 답변할 수 있도록 조정하는 방식을 알아보겠습니다.

## 채점 모델로 가독성 높이기

### 1. 선호 데이터셋을 사용한 채점 모델 만들기

